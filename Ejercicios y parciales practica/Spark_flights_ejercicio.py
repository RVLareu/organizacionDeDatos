# -*- coding: utf-8 -*-
"""flights_ejercicio.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LEzBh9sFpXVd_Nfrd60-up2R0Gxzk7OU

# PySpark RDD API
Ejercicios.
"""

!pip install pyspark
!pip install -U -q PyDrive
!apt install openjdk-8-jdk-headless -qq
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"

!pip install PyDrive

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

#idf = '1PN6TbhTwwl-hVII3P89IMbs1ashJ7BYz'
idf = '1QQ7k1Y5RvL0ZcnQuTVg0rHU6O5AK81zQ'
downloaded = drive.CreateFile({'id':idf})   # replace the id with id of file you want to access
downloaded.GetContentFile('flights.parquet') 
# Fuente del dataset: https://www.kaggle.com/divyansh22/flight-delay-prediction

from pyspark.sql import *
from pyspark.sql.functions import *
from pyspark import SparkContext
import pandas as pd
from pyspark.sql import SQLContext, SparkSession

# create the Spark Session
spark = SparkSession.builder.getOrCreate()

# create the Spark Context
sc = spark.sparkContext

sqlContext = SQLContext(sc)
rdd = sqlContext.read.parquet('flights.parquet').rdd.repartition(8).cache()

rdd.count()

rdd.takeSample(False, 2)

# DISTANCE, DEP_TIME, ARR_TIME, DAY_OF_WEEK, ORIGIN, DEST, TAIL_NUM, DAY_OF_MONTH, DAY_OF_WEEK
# Ejemplo rdd.map(lambda x: (x.ORIGIN, x.DEST))

"""### **Ejercicio 1:** Calcular la cantidad de vuelos por línea aérea (usar OP_UNIQUE_CARRIER). Calcular las diez (10) líneas aéreas con mayor cantidad de vuelos. Devolver una lista de Python con los códigos de estas 10 líneas."""

carriers = rdd.map(lambda x: (x.OP_UNIQUE_CARRIER, 1))\
.reduceByKey(lambda x,y: (x + y)).cache()
top10carriers = carriers.takeOrdered(10, lambda x: -x[1])
top10carriers

top10carriers = [x[0] for x in top10carriers]

top10carriers

"""**Ejercicio 2:** Calcular el promedio de vuelos que llegaron con 15 minutos de demora o mas (ARR_DEL15 ==1) para las 10 líneas con mas vuelos (usar el ejercicio anterior), de estas indicar las tres mejores y las tres peores."""

delays = rdd.filter(lambda x: x.OP_UNIQUE_CARRIER in top10carriers)\
.map(lambda x: (x.OP_UNIQUE_CARRIER, (float(x.ARR_DEL15), 1)))\
.reduceByKey(lambda x,y: ( x[0] + y[0], x[1] + y[1]))\
.map(lambda x: (x[0], x[1][0] / x[1][1])).collect()

sorted(delays, key = lambda x:x[1], reverse = True)[:3]

sorted(delays, key = lambda x:x[1], reverse = False)[:3]

"""**Ejercicio 3:** Calcular la cantidad de vuelos por ruta. Usando ORIGIN y DEST para la ruta. Devolver un rdd con la siguiente estructura: (RUTA, #Vuelos). Indicar además cuáles son las 10 rutas mas frecuentes y su cantidad de vuelos."""

routes = rdd.map(lambda x: ((x.ORIGIN + x.DEST),1))\
.reduceByKey(lambda x,y : x + y)\
.cache()

routes.takeOrdered(10, lambda x:-x[1])

"""**Ejercicio 4:** Consideremos ahora la cantidad de líneas aéreas que transitan cada ruta, queremos saber cuáles son las diez rutas realizadas por mayor cantidad de líneas aéreas y cuáles son las diez líneas aéreas con mayor cantidad de rutas.
Devolver: Una lista de 10 tuplas de forma (ROUTE, #CARRIERS) y Una lista de 10 tuplas de tipo (Carrier, #ROUTES)
"""

routes_by_lines = rdd.map(lambda x: ((x.ORIGIN + x.DEST, x.OP_UNIQUE_CARRIER), 1))\
.reduceByKey(lambda x,y : x + y).cache()

routes_by_lines.take(1)

routes_by_lines.map(lambda x: (x[0][0],1))\
.reduceByKey(lambda x,y: x + y)\
.takeOrdered(10, lambda x: -x[1])

routes_by_lines.map(lambda x: (x[0][1],1))\
.reduceByKey(lambda x,y: x + y).takeOrdered(10, lambda x: -x[1])

"""**Ejercicio 5:** Por cada ruta aérea calcular el promedio de tiempo de vuelo. Calculando ARR_TIME - DEP_TIME usando la función provista. Al calculo del tiempo de vuelo en minutos hay que sumarle TIMEDIFF que es la diferencia horaria entre las ciudades (en horas). Por lo tanto el calculo es:

```
hhmmtimediff(x.DEP_TIME,x.ARR_TIME) + (x.TIMEDIFF * 60)
```

Puntos extras: Además del promedio de tiempo de vuelo calcular la desviación standard del tiempo de vuelo para cada ruta.
Devolver: 
- Una lista de 10 tuplas de tipo (ROUTE, average_time)
- Una lista de 10 tuplas de tipo (ROUTE, time_std) (solo para las rutas con mas de 50 vuelos)
"""

from numpy import sqrt
# Computes time diff in format HHMM (in minutes)
def hhmmtimediff(t1, t2):
  m2 = (t2 // 100) * 60 + (t2 % 100)
  m1 = (t1 // 100) * 60 + (t1 % 100)
  return m2 - m1

routes_duration = rdd.map(lambda x: ((x.ORIGIN + x.DEST), hhmmtimediff(x.DEP_TIME, x.ARR_TIME) + (x.TIMEDIFF * 60)))\
.filter(lambda x:x[0] != 'GUMHNL')\
.filter(lambda x:x[1]>0)\
.cache()

routes_duration.take(10)

"""Para la desviacion standard usamos:
stdev = sqrt((sum_x2 / n) - (mean * mean))
"""

routes_stats = routes_duration.map(lambda x: (x[0],(x[1],x[1] ** 2,1)))\
.reduceByKey(lambda x, y : (x[0] + y[0], x[1] + y[1], x[2] + y[2]))\
.map(lambda x: (x[0], x[1][0] / x[1][2], x[1][2], sqrt((x[1][1] / x[1][2])- ((x[1][0]/x[1][2])**2))))\
.map(lambda x: Row(ROUTE=x[0],AVERAGE_DURATION=x[1],NUM_FLIGHTS=x[2],DURATION_STD=x[3] )).cache()

routes_stats.takeOrdered(10, lambda x: -x.AVERAGE_DURATION)

routes_stats.takeOrdered(10, lambda x: x.AVERAGE_DURATION)

routes_stats.takeOrdered(10, lambda x: -x.DURATION_STD)

"""**Ejercicio 6:** Para cada linea aerea contar cuantos vuelos tuvieron cuya duracion se excedio en 15 minutos o mas la duracion promedio de la ruta (para todas las lineas). Indicar las 10 mejores lineas aereas y las 10 peores de acuerdo a esta metrica."""

rdd_1 = routes_stats.map(lambda x: (x.ROUTE, x.AVERAGE_DURATION))
rdd_2 = rdd.map(lambda x: (x.ORIGIN + x.DEST,(x.OP_UNIQUE_CARRIER, hhmmtimediff(x.DEP_TIME, x.ARR_TIME) + (x.TIMEDIFF * 60))))

carrier_delays = rdd_1.join(rdd_2).cache()

carrier_delays.take(1)

carrier_delays = carrier_delays.filter(lambda x: (x[1][1][1] - x[1][0]) > 15)\
.map(lambda x: (x[1][1][0],1))\
.reduceByKey(lambda x,y: x + y)\
.cache()

carrier_delays.takeOrdered(10, lambda x: -x[1])

carrier_delays.takeOrdered(10, lambda x: x[1])

"""#CombineByKey"""

r1 = sc.parallelize([('A',1),('B',2),('C',3),('A',2),('C',28),('A',2)],4)

r1.reduceByKey(lambda x,y : x + y).collect()

r1.combineByKey(lambda x: (x,1), lambda x,y: (x[0] + y[0] ,x[1] + y[1]), lambda x,y: (x[0] + y[0], x[1] + y[1])).collect()

"""#Comentario sobre Dataframes (anecdotico)"""

sqlContext.read.parquet('flights.parquet').registerTempTable('flights')

sqlContext.sql("SELECT distinct(OP_UNIQUE_CARRIER) from flights WHERE ORIGIN = 'ORD'").show()

