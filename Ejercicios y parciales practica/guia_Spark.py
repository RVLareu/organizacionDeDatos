# -*- coding: utf-8 -*-
"""GuiaSpark.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fOuTI68ph4bM3VXPHblEIlGfF0_Kj0Xx
"""

!pip install pyspark
!pip install -U -q PyDrive
!apt update
!apt install openjdk-8-jdk-headless -qq
#!apt install default-jre
#!apt install default-jdk
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
from pyspark.sql import *
from pyspark.sql.functions import *
from pyspark import SparkContext
from pyspark.sql import SQLContext
import pandas as pd

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

# create the Spark Session
spark = SparkSession.builder.getOrCreate()

# create the Spark Context
sc = spark.sparkContext

"""# Ejercicio 1"""

documents = [
    (100812, 'A',4,"2020-05-10"),
    (100813, 'A',6,"2019-05-10"),
    (100812, 'A',6,"2000-05-10"),
    (100814, 'A',4,"2020-05-10"),
    (100812, 'A',4,"2020-05-10"),
    (100816, 'A',8,"2020-05-10"),
    (100812, 'A',8,"2000-05-10"),
    (100814, 'A',5,"2020-05-10"),
    (100812, 'A',4,"2020-05-10")
]

alumnos = [
           (100812,"Rom","an"),
           (100813,"ALu","an"),
           (100814,"TLB","an"),
           (100816,"OBJ","an")


]
notasRDD = sc.parallelize(documents)
alumnosRDD = sc.parallelize(alumnos)

"""Cuántos alumnos aprobaron al menos 1 materia en los últimos 2 años."""

notasRDD.filter(lambda x: x[2]>4).filter(lambda x: x[3].split()[0]>"2018").map(lambda x: x[0]).distinct().count()

"""Un RDD conteniendo el promedio de notas de cada alumno de la forma (padrón, promedio)."""

promedioPorPadron = notasRDD.map(lambda x: (x[0],(x[2],1))).reduceByKey(lambda x,y: (x[0]+y[0],x[1]+y[1])).map(lambda x: (x[0],x[1][0]/x[1][1]))
promedioPorPadron.collect()

"""El nombre y apellido del alumno con mejor promedio. Para esto puede utilizarse un segundo RDD alumnos con registros (padron, nombre y apellido)."""

padron = promedioPorPadron.takeOrdered(1,key=lambda x: -x[1])[0][0]
alumnosRDD.filter(lambda x: x[0]==padron).map(lambda x: (x[1],x[2])).collect()

"""# Ejercicio 2

Se tiene un RDD registros de ventas de producto con la forma (fecha de venta, código de producto, precio de venta) y en otro RDD detalle de los productos con (código de producto, descripción del producto, categoría). Se pide resolver utilizando PySpark:

# PARCIAL 2020 2C 1

Tenemos un RDD con información de recetas:
(ID_Receta, Nombre, Categoría)
Y otro RDD con los ingredientes de cada receta:
(ID_Receta, Ingrediente, Cantidad_Kg)
Queremos obtener:
a) Listar todos los ingredientes que aparecen en alguna receta que usa "pollo" indicando en
cuantas recetas el ingrediente y pollo aparecen juntos. El formato de salida es (ingrediente,
cantidad de recetas en que aparece junto con pollo). Por ejemplo, la papa aparece en 10
recetas con pollo, por lo que tendríamos (papa, 10). (50 pts)
b) Queremos obtener todos los nombres de recetas Mediterráneas que no tengan ni papa ni
pollo entre sus ingredientes.(50 pts
"""

informacionRecetas = [
                      (1,"A","mediterranea"),
                      (2,"B","caribe"),
                      (3,"C","caribe"),
                      (4,"D","caribe"),
                      (5,"E","mediterranea"),
                      (6,"F","cubana"),
                      (7,"G","mediterranea"),
                      (8,"H","mediterranea")

]

ingredientesRecetas = [
                       (1,"papa",5),
                       (1,"pollo",5),
                       
                       (2,"papa",5),
                       (2,"carne",5),

                       (3,"arroz",5),
                       (3,"pollo",5),

                       (4,"papa",5),
                       (4,"carne",5),

                       (5,"papa",5),
                       (5,"pollo",5),
                       
                       (6,"papa",5),
                       (6,"carne",5),

                       (7,"zanaohoria",5),
                       (7,"pollo",5),

                       (8,"lechuga",5),
                       (8,"carne",5)
]

informacionRecetasRDD = sc.parallelize(informacionRecetas)
ingredientesRecetasRDD = sc.parallelize(ingredientesRecetas)

"""a"""

recetasConPollo = ingredientesRecetasRDD.filter(lambda x: x[1]=="pollo").map(lambda x: (x[0],1))
recetasConPollo.collect()

ingredientesEnRecetasConPollo = recetasConPollo.join(ingredientesRecetasRDD).filter(lambda x: x[1][1]!="pollo").map(lambda x: (x[1][1],x[1][0]))
ingredientesEnRecetasConPollo.reduceByKey(lambda x,y: x + y).collect()

"""b"""

informacionRecetasMediterranea = informacionRecetasRDD.filter(lambda x: x[2] =="mediterranea")
informacionRecetasMediterranea.join(ingredientesRecetasRDD).map(lambda x: (x[1][0],x[1][1])).reduceByKey(lambda x,y: (x,y)).filter(lambda x: "pollo" not in x[1] and "papa" not in x[1]).map(lambda x: x[0]).collect()

"""# Parcial 2020 2c 1

Se tiene un RDD con la información de libros:
(id_libro, nombre, género, autor)
y otro con las ventas de distintos ejemplares de esos libros.
(id_venta, id_libro, dia_venta, mes_venta, año_venta, hora_venta, precio)
a) Indicar el género con más ventas de agosto de 2020.
b) Para los libros de los 5 géneros más vendidos en agosto de 2020, indicar el nombre del libro
que presenta mayor aumento en el número de ventas con respecto al mes anterior.

"""

libros = [(1, "Crónicas marcianas", "ciencia ficción", "Ray Bradbury"),
(2," La vuelta al mundo en ochenta días"," aventura", "Julio Verne")]

ventas =[
(100, 1, 10, "julio", 2020, "13:00:24", 300),
(101, 1, 20, "julio", 2020, "15:04:00", 300),
(102, 2, 23, "julio", 2020, "16:01:01", 250),
(103, 1, 8, "agosto", 2020, "16:22:23", 300),
(104, 1, 12, "agosto", 2020, "17:00:00", 300),
(105, 1, 12, "agosto", 2020, "17:07:07", 300),
(106, 2, 18, "agosto", 2020, "11:02:00", 250),
(107, 2, 19, "agosto", 2020, "11:42:00", 250),
(108, 2, 22, "agosto", 2020, "18:33:00", 250),
(109, 2, 22, "agosto", 2020, "18:33:00", 250)
]

librosRDD = sc.parallelize(libros)
ventasRDD = sc.parallelize(ventas)

"""a

"""

ventasAgosto2020 = ventasRDD.filter(lambda x: x[3]=="agosto" and x[4]==2020).map(lambda x: (x[1],1)).reduceByKey(lambda x,y: x+y)
ventasAgosto2020.collect()

librosCategoria = librosRDD.map(lambda x: (x[0],x[2]))
librosCategoria.join(ventasAgosto2020).takeOrdered(1,key = lambda x: -x[1][1])[0][1][0]

"""b"""

ventasTotalesJulio = ventasRDD.filter(lambda x: x[3]=="julio" or x[3]=="agosto").map(lambda x: (x[1],(7,1)) if x[3]=="julio" else (x[1],(8,1)))
ventasTotalesJulio.reduceByKey(lambda x,y: (x[0],x[1]-y[1]) if (x[0]>y[0]) else )