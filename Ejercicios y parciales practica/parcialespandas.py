# -*- coding: utf-8 -*-
"""ParcialesPandas.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1atj8-yuOPL5psZCaEJHhKS-VhTPyaDXd
"""

import pandas as pd

"""2) Un importante broker de compra y venta de vehiculos online se encuentra dando sus primeros pasos en la preparación de su algoritmo de pricing, es por eso que se encuentra generando algunos features iniciales para experimentar con distintos algoritmos de machine learning. Para ello cuenta con un archivo con información de todas las transacciones que tuvo en su primer
año de operación en el formato 

(transaction_id, timestamp, vehicle_model_id, price).

Por otro lado cuenta con información que fue extrayendo a partir de scrapping durante el último año en el formato

(timestamp, source, vehicle_model_id, price).

La información puede venir de múltiples fuentes (source), que pueden ser por ejemplo distintos sitios de marketplace o clasificados. Luego de un intenso trabajo previo ha podido unificar los modelos de vehículos que utiliza para
sus transacciones con la información que ha podido obtener de otros competidores mediante scrapping. Muchos de los modelos disponibles en la información de scrapping no han sido aún comercializados por la empresa, pero se sabe que se cuenta con precios scrapeados de todos los modelos que se vendieron.
Se pide generar utilizando Pandas un dataframe que tenga el siguiente formato

(vehicle_model_id, ext_mean_price, ext_std_price, int_mean_price,
int_std_price)

 siendo:

- mean_price: precio promedio para ese vehículo.
- std_price: desvío estándar del precio para ese vehículo.

y los prefijo ext_ y int_ indicando que deben ser calculado sobre respectivamente datos
externos (los obtenido vía scraping) y datos internos (los de las transacciones). (***) (15pts)
"""

transacciones = pd.DataFrame({
    "transaction_id":[1,2,3,4,5,6,7,8],
    "timestamp":["13:00:03","13:00:03","13:00:03","13:00:03","13:00:03","13:00:03","13:00:03","13:00:03"],
    "vehicle_model_id":["V1","V2","V2","V3","V1","V4","V4","V4"],
    "price":[10,20,22,12,12,30,40,34]
    

})

scrapping = pd.DataFrame({
    "timestamp":["13:00:03","13:00:03","13:00:03","13:00:03","13:00:03","13:00:03","13:00:03","13:00:03","13:00:03"],
    "source":["s1","s1","s1","s2","s2","s2","s3","s3","s3"],
    "vehicle_model_id":["V1","V2","V2","V4","V6","V7","V3","V1","V5"],
    "price":[15,20,10,5,15,20,30,40,13]

})

tablaInterna = transacciones.groupby("vehicle_model_id").agg({"price":["mean","std"]})
tablaInterna.reset_index(inplace=True)
tablaInterna.columns=["vehicle_model_id","int_mean_price","int_std_price"]
tablaInterna

tablaExterna = scrapping.groupby("vehicle_model_id").agg({"price":["mean","std"]})
tablaExterna.reset_index(inplace=True)
tablaExterna.columns=["vehicle_model_id","ext_mean_price","ext_std_price"]
tablaExterna

tablaConjunta = tablaExterna.merge(tablaInterna,how="inner")
tablaConjunta

"""2) Tokyo Telemessage se encuentra analizando la posibilidad de dar
finalmente de baja su servicio de pager que mantiene desde la década de
1980 . Los pagers son un dispositivo de mensajería que realiza un ‘beep’ al
recibir un mensaje de texto de un número limitado de caracteres. Para
poder enviar un mensaje, uno debe llamar a un número telefónico que
representa al pager dejando el mensaje a una operadora.
Para el analisis se cuenta con dos csv’s: clientes.csv del siguiente formato

(id_pager, numero_telefono, codigo_de_area,
fecha_creacion_cuenta, nombre_cliente, region,
categoria_cliente)

 y eventos.csv

(año,mes,dia,hora,minutos,segundos, id_pager, mensaje,
numero_origen).

Como parte del análisis se desea responder:

a. ¿Cuál es la región que aún tiene activos la mayor cantidad de
pagers, entendiendo como activo aquellos que recibieron por lo
menos un mensaje en el último mes?

b. ¿Cuál es el porcentaje de pagers activos que solamente reciben
mensajes únicamente de una persona (es decir, siempre desde
el mismo número de origen)?

Utilizar pandas para responder las anteriores preguntas.
"""

clientes = pd.DataFrame({
    "id_pager":["p1","p2","p3","p4","p5","p6","p7","p8"],
    "numero_telefono":[41,42,43,44,45,46,47,48],
    "codigo_de_area":[1,2,3,4,5,6,7,8],
    "fecha_creacion_cuenta":[10,10,10,11,11,11,12,12],
    "nombre_cliente":["a","b","c","d","e","f","g","h"],
    "region":["URU","URU","URU","ARG","ARG","ARG","BRA","BRA"],
    "categoria_cliente":[1,2,3,4,5,1,2,3]
})

eventos = pd.DataFrame({
    "año":[2020,2020,2020,2020,2020,2020,2020,2020,2020,2020],
    "mes":["agosto","agosto","agosto","agosto","agosto","agosto","enero","enero","enero","enero"],
    "dia":[1,2,3,4,5,6,7,8,9,10],
    "hora":[1,2,3,4,5,6,7,8,9,10],
    "minutos":[1,2,3,4,5,6,7,8,9,10],
    "segundos":[1,2,3,4,5,6,7,8,9,10],
    "id_pager":["p1","p3","p5","p1","p2","p1","p1","p8","p4","p4"],
    "mensaje":["aa","ba","ca","da","ea","fa","ga","ha","ha","ha"],
    "numero_origen":[42,44,48,45,44,43,42,41,46,45]
})

"""###a)"""

eventos_id = eventos[["id_pager","numero_origen","mes","año"]]
eventos_id = eventos_id[(eventos_id["año"]==2020) & (eventos_id["mes"]=="agosto")  ]
eventos_id = eventos_id[["id_pager","numero_origen"]]
eventos_id

clientes_id = clientes[["id_pager","numero_telefono","region"]]
clientes_id

clientes_activos = clientes_id.merge(eventos_id,how="inner")
clientes_activos

clientes_activos.groupby("region").agg({"numero_telefono":"count"}).nlargest(1,"numero_telefono")

"""###b)"""

llamados_por_id = clientes_activos.groupby("id_pager").agg({"numero_origen":"count"})
llamados_por_id

sum(llamados_por_id["numero_origen"]==1)/llamados_por_id.shape[0]

"""2) Un importante servicio de monitoreo de aplicaciones cloud, sufrió un importante incidente en las últimas semanas por lo cual está conduciendo una investigación. Nuestro equipo participa en el análisis de forma externa para lo cual nos provee los siguientes dataframes en csv:

- metrics.csv describiendo información de métricas obtenidas. El mismo tiene el formato ('client_id', 'integration_id' ,'metric', 'timestamp', 'value') donde la columna ‘metric’ indica el nombre de una métrica que se registra en un cierto momento ('timestamp') cuyo valor se guarda en la columna 'value'.

- clients.csv con información sobre el cliente, con el formato ('client_id, 'account_number', 'name') donde 'account_number' indica el número de cuenta de cliente y 'name' el nombre del mismo.

Como miembro de nuestro equipo es necesario que obtengas las siguientes métricas para aportar insights a nuestro análisis:

a) Calcular el valor promedio de las metricas 'aws.vpc.network_out', 'aws.vpc.network_in', 'aws.vpc.network_rate' para los clientes de ‘account_number’ mayor al '25679247' devolviendo el resultado en el siguiente formato (account_number, 'aws.vpc.network_out_mean', 'aws.vpc.network_in_mean', 'aws.vpc.network_rate_mean')(15pts)

b) Calcular la diferencia entre el valor promedio obtenido en cada métrica por cada cliente, y el valor promedio general de esa métrica (sin utilizar group by) (10pts)

"""

metrics = pd.DataFrame({
    "client_id":["c1","c1","c3","c2","c3","c4","c4","c4","c5","c6","c6"],
    "inegration_id":[1,2,3,4,5,6,7,8,9,10,11],
    "metric":['aws.vpc.network_out','aws.vpc.network_out','aws.vpc.network_out','aws.vpc.network_out','aws.vpc.network_in','aws.vpc.network_in','aws.vpc.network_in', 'aws.vpc.network_rate', 'aws.vpc.network_rate', 'aws.vpc.network_rate',"otra"],
    "timestamp":["12:01:03","12:01:03","12:01:03","12:01:03","12:01:03","12:01:03","12:01:03","12:01:03","12:01:03","12:01:03","12:01:03"],
    "value":[12,13,14,19,43,2,32,65,8,32,1]
})

clients = pd.DataFrame({
    "client_id":["c1","c2","c3","c4","c5","c6","c7","c8"],
    "account_number":[25679249,25679245,25679250,25679275,25679290,25679299,25679248,25679289],
    "name":["n1","n2","n3","n4","n5","n6","n7","n8"]
})

"""###a)"""

clientes_mayores = clients[clients["account_number"]>25679247]
clientes_mayores

metrics = metrics[ (metrics["metric"]=="aws.vpc.network_in") | (metrics["metric"]=="aws.vpc.network_rate") | (metrics["metric"]=="aws.vpc.network_out") ]
metrics = metrics[["client_id","metric","value"]]
metrics

metric_client = metrics.merge(clientes_mayores)
metric_client

res = metric_client.groupby(["account_number","metric"]).agg({"value":"mean"})
res

res = res.unstack()

res.columns = ["aws.vpc.network_in_mean","aws.vpc.network_out_mean","aws.vpc.network_rate_mean"]
res

res.reset_index(inplace=True)
res

res = res[["account_number","aws.vpc.network_out_mean","aws.vpc.network_in_mean","aws.vpc.network_rate_mean"]]
res

"""###b)"""

metrics_client_mean = metrics.pivot_table(index="client_id",columns="metric",values="value",aggfunc="mean")
metrics_client_mean

metrics.pivot_table(columns="metric",values="value",aggfunc="mean")

network_in_mean = metrics.pivot_table(columns="metric",values="value",aggfunc="mean")["aws.vpc.network_in"][0]
network_out_mean = metrics.pivot_table(columns="metric",values="value",aggfunc="mean")["aws.vpc.network_out"][0]
network_rate_mean = metrics.pivot_table(columns="metric",values="value",aggfunc="mean")["aws.vpc.network_rate"][0]

metrics_client_mean["net_in_diff"] = metrics_client_mean["aws.vpc.network_in"]-network_in_mean
metrics_client_mean["net_out_diff"] = metrics_client_mean["aws.vpc.network_out"]-network_out_mean
metrics_client_mean["net_rate_diff"] = metrics_client_mean["aws.vpc.network_rate"]-network_rate_mean

metrics_client_mean